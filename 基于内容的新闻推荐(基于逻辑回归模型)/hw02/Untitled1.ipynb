{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step01:导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from gensim.models import word2vec\n",
    "import gensim\n",
    "import nltk.tokenize as tk\n",
    "from nltk.corpus import stopwords \n",
    "import nltk.stem.snowball as sb\n",
    "import nltk.stem.porter as pt\n",
    "import nltk.stem.lancaster as lc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import copy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_u = pd.read_table(\"train.tsv\")\n",
    "test_n = pd.read_table(\"test_news.tsv\")\n",
    "test_u = pd.read_table(\"test.tsv\")\n",
    "train_n = pd.read_table(\"train_news.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nid</th>\n",
       "      <th>Category</th>\n",
       "      <th>SubCategory</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N55528</td>\n",
       "      <td>lifestyle</td>\n",
       "      <td>lifestyleroyals</td>\n",
       "      <td>The Brands Queen Elizabeth, Prince Charles, an...</td>\n",
       "      <td>Shop the notebooks, jackets, and more that the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N18955</td>\n",
       "      <td>health</td>\n",
       "      <td>medical</td>\n",
       "      <td>Dispose of unwanted prescription drugs during ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N61837</td>\n",
       "      <td>news</td>\n",
       "      <td>newsworld</td>\n",
       "      <td>The Cost of Trump's Aid Freeze in the Trenches...</td>\n",
       "      <td>Lt. Ivan Molchanets peeked over a parapet of s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N53526</td>\n",
       "      <td>health</td>\n",
       "      <td>voices</td>\n",
       "      <td>I Was An NBA Wife. Here's How It Affected My M...</td>\n",
       "      <td>I felt like I was a fraud, and being an NBA wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N38324</td>\n",
       "      <td>health</td>\n",
       "      <td>medical</td>\n",
       "      <td>How to Get Rid of Skin Tags, According to a De...</td>\n",
       "      <td>They seem harmless, but there's a very good re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42411</th>\n",
       "      <td>N63550</td>\n",
       "      <td>lifestyle</td>\n",
       "      <td>lifestyleroyals</td>\n",
       "      <td>Why Kate &amp; Meghan Were on Different Balconies ...</td>\n",
       "      <td>There's no scandal here. It's all about the or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42412</th>\n",
       "      <td>N30345</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>entertainment-celebrity</td>\n",
       "      <td>See the stars at the 2019 Baby2Baby gala</td>\n",
       "      <td>Stars like Chrissy Teigen and Kate Hudson supp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42413</th>\n",
       "      <td>N30135</td>\n",
       "      <td>news</td>\n",
       "      <td>newsgoodnews</td>\n",
       "      <td>Tennessee judge holds lawyer's baby as he swea...</td>\n",
       "      <td>Tennessee Court of Appeals Judge Richard Dinki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42414</th>\n",
       "      <td>N44276</td>\n",
       "      <td>autos</td>\n",
       "      <td>autossports</td>\n",
       "      <td>Best Sports Car Deals for October</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42415</th>\n",
       "      <td>N39563</td>\n",
       "      <td>sports</td>\n",
       "      <td>more_sports</td>\n",
       "      <td>Shall we dance: Sports stars shake their leg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42416 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Nid       Category              SubCategory  \\\n",
       "0      N55528      lifestyle          lifestyleroyals   \n",
       "1      N18955         health                  medical   \n",
       "2      N61837           news                newsworld   \n",
       "3      N53526         health                   voices   \n",
       "4      N38324         health                  medical   \n",
       "...       ...            ...                      ...   \n",
       "42411  N63550      lifestyle          lifestyleroyals   \n",
       "42412  N30345  entertainment  entertainment-celebrity   \n",
       "42413  N30135           news             newsgoodnews   \n",
       "42414  N44276          autos              autossports   \n",
       "42415  N39563         sports              more_sports   \n",
       "\n",
       "                                                   Title  \\\n",
       "0      The Brands Queen Elizabeth, Prince Charles, an...   \n",
       "1      Dispose of unwanted prescription drugs during ...   \n",
       "2      The Cost of Trump's Aid Freeze in the Trenches...   \n",
       "3      I Was An NBA Wife. Here's How It Affected My M...   \n",
       "4      How to Get Rid of Skin Tags, According to a De...   \n",
       "...                                                  ...   \n",
       "42411  Why Kate & Meghan Were on Different Balconies ...   \n",
       "42412           See the stars at the 2019 Baby2Baby gala   \n",
       "42413  Tennessee judge holds lawyer's baby as he swea...   \n",
       "42414                  Best Sports Car Deals for October   \n",
       "42415       Shall we dance: Sports stars shake their leg   \n",
       "\n",
       "                                                Abstract  \n",
       "0      Shop the notebooks, jackets, and more that the...  \n",
       "1                                                    NaN  \n",
       "2      Lt. Ivan Molchanets peeked over a parapet of s...  \n",
       "3      I felt like I was a fraud, and being an NBA wi...  \n",
       "4      They seem harmless, but there's a very good re...  \n",
       "...                                                  ...  \n",
       "42411  There's no scandal here. It's all about the or...  \n",
       "42412  Stars like Chrissy Teigen and Kate Hudson supp...  \n",
       "42413  Tennessee Court of Appeals Judge Richard Dinki...  \n",
       "42414                                                NaN  \n",
       "42415                                                NaN  \n",
       "\n",
       "[42416 rows x 5 columns]"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 得到训练集top10，和测试集top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopN(petro,N):\n",
    "    res = []\n",
    "    for i in range(0,len(petro)):\n",
    "        res.extend(ImpressT(petro[\"Impression\"][i]))\n",
    "    counter = {}\n",
    "    for i in res:\n",
    "        counter[i] = counter.get(i,0)+1\n",
    "    topN = sorted(counter,key = counter.get,reverse = True)[:N]\n",
    "    return topN\n",
    "trainTop = getTopN(train_u,10)\n",
    "#训练集热门新闻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gethistory(i):\n",
    "    res = (test_u[\"History\"][i]).split(\" \")\n",
    "    return res\n",
    "def getTopNtest(petro,N):\n",
    "    res = []\n",
    "    for i in range(0,len(petro)):\n",
    "        res.extend(gethistory(i))\n",
    "    counter = {}\n",
    "    for i in res:\n",
    "        counter[i] = counter.get(i,0)+1\n",
    "    topN = sorted(counter,key = counter.get,reverse = True)[:N]\n",
    "    return topN\n",
    "testTop = getTopNtest(test_u,10)\n",
    "#测试集热门新闻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Cost of Trump's Aid Freeze in the Trenches...</td>\n",
       "      <td>Lt. Ivan Molchanets peeked over a parapet of s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "2  The Cost of Trump's Aid Freeze in the Trenches...   \n",
       "\n",
       "                                            Abstract  \n",
       "2  Lt. Ivan Molchanets peeked over a parapet of s...  "
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_n.loc[train_n[\"Nid\"]==\"N61837\",[\"Title\",\"Abstract\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获得正样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['N357', 'N46029', 'N56598']"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ImpressT(rec):\n",
    "    res = []\n",
    "    rec = rec.split(' ')\n",
    "    for i in rec:\n",
    "        if i[-1]=='1':\n",
    "            res.append(i[:-2])\n",
    "    return res\n",
    "def ImpressF(rec):\n",
    "    res = []\n",
    "    rec = rec.split(' ')\n",
    "    for i in rec:\n",
    "        if i[-1]=='0':\n",
    "            res.append(i[:-2])\n",
    "    return res\n",
    "Impress(train_u[\"Impression\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newtrainT(petro):\n",
    "    res = {}\n",
    "    for i in range(0,len(petro)):\n",
    "        res[petro[\"Uid\"][i]]=ImpressT(petro[\"Impression\"][i])\n",
    "    return res\n",
    "def newtrainF(petro):\n",
    "    res = {}\n",
    "    for i in range(0,len(petro)):\n",
    "        res[petro[\"Uid\"][i]]=ImpressF(petro[\"Impression\"][i])\n",
    "    return res\n",
    "trainT = newtrainT(train_u) #每个user的正样本\n",
    "trainF = newtrainF(train_u) #每个user的负样本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 结构化特征向量定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'autos': 10,\n",
       " 'entertainment': 20,\n",
       " 'finance': 30,\n",
       " 'foodanddrink': 40,\n",
       " 'games': 50,\n",
       " 'health': 60,\n",
       " 'kids': 70,\n",
       " 'lifestyle': 80,\n",
       " 'middleeast': 90,\n",
       " 'movies': 100,\n",
       " 'music': 110,\n",
       " 'news': 120,\n",
       " 'northamerica': 130,\n",
       " 'sports': 140,\n",
       " 'travel': 150,\n",
       " 'tv': 160,\n",
       " 'video': 170,\n",
       " 'weather': 180}"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CateCate  = np.unique(np.hstack((train_n[\"Category\"].unique(),test_n[\"Category\"].unique())))\n",
    "CateScore = {}\n",
    "temp = 10\n",
    "for i in CateCate:\n",
    "    CateScore[i] = temp\n",
    "    temp+=10\n",
    "CateScore #每个Cate的值对应   字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ads-latingrammys': 10,\n",
       " 'ads-lung-health': 20,\n",
       " 'advice': 30,\n",
       " 'animals': 40,\n",
       " 'autosbuying': 50,\n",
       " 'autoscartech': 60,\n",
       " 'autosclassics': 70,\n",
       " 'autoscompact': 80,\n",
       " 'autosenthusiasts': 90,\n",
       " 'autoshybrids': 100,\n",
       " 'autoslosangeles': 110,\n",
       " 'autosluxury': 120,\n",
       " 'autosmidsize': 130,\n",
       " 'autosmotorcycles': 140,\n",
       " 'autosnews': 150,\n",
       " 'autosownership': 160,\n",
       " 'autospassenger': 170,\n",
       " 'autosresearch': 180,\n",
       " 'autosresearchguides': 190,\n",
       " 'autosreview': 200,\n",
       " 'autossema': 210,\n",
       " 'autossports': 220,\n",
       " 'autossuvs': 230,\n",
       " 'autostokyo': 240,\n",
       " 'autostrucks': 250,\n",
       " 'autosvans': 260,\n",
       " 'autosvideonew': 270,\n",
       " 'autosvideos': 280,\n",
       " 'awards': 290,\n",
       " 'awardstyle': 300,\n",
       " 'baseball': 310,\n",
       " 'baseball_mlb': 320,\n",
       " 'baseball_mlb_videos': 330,\n",
       " 'basketball_nba': 340,\n",
       " 'basketball_nba_videos': 350,\n",
       " 'basketball_ncaa': 360,\n",
       " 'basketball_ncaa_videos': 370,\n",
       " 'basketball_wnba': 380,\n",
       " 'beverages': 390,\n",
       " 'boxing': 400,\n",
       " 'boxing-mma': 410,\n",
       " 'cardio': 420,\n",
       " 'career-news': 430,\n",
       " 'causes': 440,\n",
       " 'causes-animals': 450,\n",
       " 'causes-disaster-relief': 460,\n",
       " 'causes-environment': 470,\n",
       " 'causes-food-insecurity': 480,\n",
       " 'causes-green-living': 490,\n",
       " 'causes-military-appreciation': 500,\n",
       " 'causes-poverty': 510,\n",
       " 'celebhub': 520,\n",
       " 'celebrity': 530,\n",
       " 'celebritynews': 540,\n",
       " 'cma-awards': 550,\n",
       " 'cocktails': 560,\n",
       " 'comedy': 570,\n",
       " 'company-news': 580,\n",
       " 'cooking': 590,\n",
       " 'cookingschool': 600,\n",
       " 'downtime': 610,\n",
       " 'elections-2020-us': 620,\n",
       " 'empowering-the-planet': 630,\n",
       " 'entertainment-books': 640,\n",
       " 'entertainment-celebrity': 650,\n",
       " 'entertainmentmusic': 660,\n",
       " 'entertainmenttv': 670,\n",
       " 'factcheck': 680,\n",
       " 'finance-auto-insurance': 690,\n",
       " 'finance-billstopay': 700,\n",
       " 'finance-career': 710,\n",
       " 'finance-career-education': 720,\n",
       " 'finance-companies': 730,\n",
       " 'finance-credit': 740,\n",
       " 'finance-education': 750,\n",
       " 'finance-healthcare': 760,\n",
       " 'finance-home-loans': 770,\n",
       " 'finance-homesandpropertysection': 780,\n",
       " 'finance-insidetheticker': 790,\n",
       " 'finance-insurance': 800,\n",
       " 'finance-mutual-funds': 810,\n",
       " 'finance-real-estate': 820,\n",
       " 'finance-retirement': 830,\n",
       " 'finance-savemoney': 840,\n",
       " 'finance-saving-investing': 850,\n",
       " 'finance-small-business': 860,\n",
       " 'finance-startinvesting': 870,\n",
       " 'finance-taxes': 880,\n",
       " 'finance-technology': 890,\n",
       " 'finance-top-stocks': 900,\n",
       " 'finance-video': 910,\n",
       " 'financenews': 920,\n",
       " 'fitness': 930,\n",
       " 'foodanddrink': 940,\n",
       " 'foodnews': 950,\n",
       " 'foodrecipes': 960,\n",
       " 'foodtips': 970,\n",
       " 'football_ncaa': 980,\n",
       " 'football_ncaa_videos': 990,\n",
       " 'football_nfl': 1000,\n",
       " 'football_nfl_videos': 1010,\n",
       " 'fun': 1020,\n",
       " 'games': 1030,\n",
       " 'games-news': 1040,\n",
       " 'gaming': 1050,\n",
       " 'golf': 1060,\n",
       " 'golfvideos': 1070,\n",
       " 'halloween': 1080,\n",
       " 'health-cancer': 1090,\n",
       " 'health-news': 1100,\n",
       " 'healthagingwell': 1110,\n",
       " 'healthnews': 1120,\n",
       " 'healthyliving': 1130,\n",
       " 'holidays': 1140,\n",
       " 'hollywood': 1150,\n",
       " 'humor': 1160,\n",
       " 'icehockey_nhl': 1170,\n",
       " 'indepth': 1180,\n",
       " 'internationaltravel': 1190,\n",
       " 'lifestyle': 1200,\n",
       " 'lifestyle-news-feature': 1210,\n",
       " 'lifestyle-wedding': 1220,\n",
       " 'lifestyleanimals': 1230,\n",
       " 'lifestylebeauty': 1240,\n",
       " 'lifestylebuzz': 1250,\n",
       " 'lifestylecareer': 1260,\n",
       " 'lifestylecelebstyle': 1270,\n",
       " 'lifestylecleaningandorganizing': 1280,\n",
       " 'lifestyledecor': 1290,\n",
       " 'lifestyledidyouknow': 1300,\n",
       " 'lifestylediy': 1310,\n",
       " 'lifestylefamily': 1320,\n",
       " 'lifestylefamilyandrelationships': 1330,\n",
       " 'lifestylefashion': 1340,\n",
       " 'lifestylehomeandgarden': 1350,\n",
       " 'lifestylehoroscope': 1360,\n",
       " 'lifestylehoroscopefish': 1370,\n",
       " 'lifestylelovesex': 1380,\n",
       " 'lifestylemarriage': 1390,\n",
       " 'lifestylemindandsoul': 1400,\n",
       " 'lifestyleparenting': 1410,\n",
       " 'lifestylepets': 1420,\n",
       " 'lifestylepetsanimals': 1430,\n",
       " 'lifestylerelationships': 1440,\n",
       " 'lifestyleroyals': 1450,\n",
       " 'lifestyleshopping': 1460,\n",
       " 'lifestyleshoppinghomegarden': 1470,\n",
       " 'lifestylesmartliving': 1480,\n",
       " 'lifestylestyle': 1490,\n",
       " 'lifestyletravel': 1500,\n",
       " 'lifestylevideo': 1510,\n",
       " 'lifestyleweddings': 1520,\n",
       " 'lifestylewhatshot': 1530,\n",
       " 'markets': 1540,\n",
       " 'medical': 1550,\n",
       " 'mentalhealth': 1560,\n",
       " 'middleeast-top-stories': 1570,\n",
       " 'mma': 1580,\n",
       " 'mmaufc': 1590,\n",
       " 'more_sports': 1600,\n",
       " 'movienews': 1610,\n",
       " 'movies-awards': 1620,\n",
       " 'movies-celebrity': 1630,\n",
       " 'movies-gallery': 1640,\n",
       " 'movies-oscars': 1650,\n",
       " 'movievideo': 1660,\n",
       " 'music-awards': 1670,\n",
       " 'music-celebrity': 1680,\n",
       " 'music-gallery': 1690,\n",
       " 'music-grammys': 1700,\n",
       " 'music-reviews': 1710,\n",
       " 'musicnews': 1720,\n",
       " 'musicvideos': 1730,\n",
       " 'narendramodi_opinion': 1740,\n",
       " 'news': 1750,\n",
       " 'newsbusiness': 1760,\n",
       " 'newscrime': 1770,\n",
       " 'newselection2020': 1780,\n",
       " 'newsfactcheck': 1790,\n",
       " 'newsgoodnews': 1800,\n",
       " 'newsnational': 1810,\n",
       " 'newsoffbeat': 1820,\n",
       " 'newsopinion': 1830,\n",
       " 'newsother': 1840,\n",
       " 'newsphotos': 1850,\n",
       " 'newspolitics': 1860,\n",
       " 'newsrealestate': 1870,\n",
       " 'newsscience': 1880,\n",
       " 'newsscienceandtechnology': 1890,\n",
       " 'newstechnology': 1900,\n",
       " 'newstrends': 1910,\n",
       " 'newstvmedia': 1920,\n",
       " 'newsus': 1930,\n",
       " 'newsvideo': 1940,\n",
       " 'newsvideos': 1950,\n",
       " 'newsweather': 1960,\n",
       " 'newsworld': 1970,\n",
       " 'newsworldpolitics': 1980,\n",
       " 'northamerica-video': 1990,\n",
       " 'nutrition': 2000,\n",
       " 'olympics-videos': 2010,\n",
       " 'othersports': 2020,\n",
       " 'outdoors': 2030,\n",
       " 'people-places': 2040,\n",
       " 'peopleandplaces': 2050,\n",
       " 'personalfinance': 2060,\n",
       " 'photos': 2070,\n",
       " 'popculture': 2080,\n",
       " 'pregnancyparenting': 2090,\n",
       " 'quickandeasy': 2100,\n",
       " 'racing': 2110,\n",
       " 'recipes': 2120,\n",
       " 'relationships': 2130,\n",
       " 'restaurantsandnews': 2140,\n",
       " 'retirement': 2150,\n",
       " 'reviews': 2160,\n",
       " 'science': 2170,\n",
       " 'seasonal': 2180,\n",
       " 'shop-all': 2190,\n",
       " 'shop-apparel': 2200,\n",
       " 'shop-books-movies-tv': 2210,\n",
       " 'shop-computers-electronics': 2220,\n",
       " 'shop-holidays': 2230,\n",
       " 'shop-home-goods': 2240,\n",
       " 'soccer': 2250,\n",
       " 'soccer_bund': 2260,\n",
       " 'soccer_epl': 2270,\n",
       " 'soccer_mls': 2280,\n",
       " 'spendingandborrowing': 2290,\n",
       " 'sports': 2300,\n",
       " 'sports_news': 2310,\n",
       " 'strength': 2320,\n",
       " 'technologyinvesting': 2330,\n",
       " 'tennis': 2340,\n",
       " 'tennis_intl': 2350,\n",
       " 'tipsandtricks': 2360,\n",
       " 'topnews': 2370,\n",
       " 'travel': 2380,\n",
       " 'travel-adventure-travel': 2390,\n",
       " 'travel-points-rewards': 2400,\n",
       " 'travel-videos': 2410,\n",
       " 'travelarticle': 2420,\n",
       " 'travelnews': 2430,\n",
       " 'traveltips': 2440,\n",
       " 'traveltripideas': 2450,\n",
       " 'traveltrivia': 2460,\n",
       " 'tunedin': 2470,\n",
       " 'tv': 2480,\n",
       " 'tv-celebrity': 2490,\n",
       " 'tv-gallery': 2500,\n",
       " 'tv-golden-globes': 2510,\n",
       " 'tv-golden-globes-video': 2520,\n",
       " 'tv-recaps': 2530,\n",
       " 'tv-reviews': 2540,\n",
       " 'tvnews': 2550,\n",
       " 'tvvideos': 2560,\n",
       " 'ustravel': 2570,\n",
       " 'video': 2580,\n",
       " 'videos': 2590,\n",
       " 'viral': 2600,\n",
       " 'voices': 2610,\n",
       " 'watch': 2620,\n",
       " 'weatherfullscreenmaps': 2630,\n",
       " 'weathertopstories': 2640,\n",
       " 'weight-loss': 2650,\n",
       " 'weightloss': 2660,\n",
       " 'wellness': 2670,\n",
       " 'wines': 2680,\n",
       " 'wonder': 2690,\n",
       " 'yearinoffbeatgoodnews': 2700}"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SubCate  = np.unique(np.hstack((train_n[\"SubCategory\"].unique(),test_n[\"SubCategory\"].unique())))\n",
    "SubScore = {}\n",
    "temp = 10\n",
    "for i in SubCate:\n",
    "    SubScore[i] = temp\n",
    "    temp+=10\n",
    "SubScore  #每个Subcate的值对应  字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "#文本预处理\n",
    "pattern = re.compile(\"[^a-zA-Z0-9\\n ]\") #用于去除标点\n",
    "def sentence2word(text):\n",
    "    text = re.sub(pattern,\"\",text).lower() #转换为小写，并去除标点\n",
    "    tokens = tk.word_tokenize(text) #进行单词切分\n",
    "    return tokens\n",
    "def getwordlist(txt_train):\n",
    "    for i in range(0,txt_train.shape[0]):\n",
    "        txt_train['Title'][i] = sentence2word(str(txt_train['Title'][i]))\n",
    "        txt_train['Abstract'][i] = sentence2word(str(txt_train['Abstract'][i]))\n",
    "    word_list = list(txt_train['Abstract'])+list(txt_train['Title'])\n",
    "    return word_list\n",
    "wlist = getwordlist(train_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "#得到词向量模型\n",
    "w2v_model = gensim.models.Word2Vec(wlist, vector_size=20, window=5, min_count=1, workers=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = w2v_model.wv.index_to_key #得到单词表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "#得到句向量\n",
    "def sen2vec(text):\n",
    "    i=0\n",
    "    lis = sentence2word(text)\n",
    "    #print(lis)\n",
    "    sum = np.zeros(20,dtype=np.float32)\n",
    "    for word in lis:\n",
    "        if word in vocab:\n",
    "            sum += w2v_model.wv.vectors[w2v_model.wv.key_to_index[word]]\n",
    "            i+=1\n",
    "    try:\n",
    "        sum = sum/i\n",
    "    except ZeroDivisionError:\n",
    "        sum = sum\n",
    "    if math.isnan(sum[0]):\n",
    "        return np.zeros(20,dtype=np.float32)\n",
    "    #print(sum,i)\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [\"CateS\",\"SubS\"]\n",
    "for i in range(20):\n",
    "    col.append(\"TitVec\"+str(i))\n",
    "for i in range(20):\n",
    "    col.append(\"AbsVec\"+str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 得到新闻结构特征向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "def charicVec(news):\n",
    "    col = [\"CateS\",\"SubS\"]\n",
    "    for i in range(20):\n",
    "        col.append(\"TitVec\"+str(i))\n",
    "    for i in range(20):\n",
    "        col.append(\"AbsVec\"+str(i))\n",
    "    temp = []\n",
    "    res = []\n",
    "    length = news.shape[0]\n",
    "    for i in range(0,length):\n",
    "        temp = []\n",
    "        temp.append(CateScore[news[\"Category\"][i]])\n",
    "        temp.append(SubScore[news[\"SubCategory\"][i]])\n",
    "        if (news[\"Title\"][i]) != np.nan:\n",
    "            temp.extend(sen2vec(str(news[\"Title\"][i])))\n",
    "        else:\n",
    "            temp.extend(sum = np.zeros(20,dtype=np.float32))\n",
    "        if (news[\"Abstract\"][i]) != np.nan:\n",
    "            temp.extend(sen2vec(str(news[\"Abstract\"][i])))\n",
    "        else:\n",
    "            temp.extend(sum = np.zeros(20,dtype=np.float32))\n",
    "        res.append(copy.deepcopy(temp))\n",
    "    res = pd.DataFrame(res,columns=col)\n",
    "    return res\n",
    "trainChar = charicVec(train_n)\n",
    "testChar = charicVec(test_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nC = pd.concat([train_n,trainChar],axis=1)\n",
    "train_nC.drop([\"Category\",\"SubCategory\",\"Title\",\"Abstract\"],axis=1,inplace=True)\n",
    "#训练集新闻特征向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nC = pd.concat([test_n,testChar],axis=1)\n",
    "test_nC.drop([\"Category\",\"SubCategory\",\"Title\",\"Abstract\"],axis=1,inplace=True)\n",
    "#测试集新闻特征向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.40000000e+02,  1.00000000e+03,  1.12987089e+00,\n",
       "        -7.24367082e-01,  1.60059357e+00,  1.20050967e+00,\n",
       "         2.49791220e-02, -1.23277020e+00, -5.00418723e-01,\n",
       "         7.83931732e-01, -2.00756812e+00, -2.02456787e-01,\n",
       "         7.97964573e-01,  9.00134742e-01,  6.51192009e-01,\n",
       "         4.64457005e-01, -5.49746454e-01,  1.16794896e+00,\n",
       "        -9.48290765e-01,  1.21693611e+00,  1.22371280e+00,\n",
       "        -1.51993608e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00]])"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#某新闻特征向量\n",
    "test_nC.loc[test_nC[\"Nid\"]==\"N3347\",col].values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用于得到正负样本的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "#得到每个用户his\n",
    "def gethistory(petro): \n",
    "    res = {}\n",
    "    for i in range(0,len(petro)):\n",
    "        res[petro[\"Uid\"][i]] = petro[\"History\"][i].split(\" \")  \n",
    "    return res\n",
    "#得到每个用户未读的热门新闻\n",
    "def getNeg_train(petro,top):\n",
    "    res = {}\n",
    "    for i in range(0,len(petro)): \n",
    "        temp = train_history[petro[\"Uid\"][i]] ###修改his可以获得训练集与测试集不同负样本\n",
    "        tempNe = []\n",
    "        for e in top:\n",
    "            if e not in temp:\n",
    "                tempNe.append(e)\n",
    "        res[petro[\"Uid\"][i]] = copy.deepcopy(tempNe)\n",
    "    return res\n",
    "#得到每个用户未读的热门新闻\n",
    "def getNeg_test(petro,top):\n",
    "    res = {}\n",
    "    for i in range(0,len(petro)): \n",
    "        temp = test_history[petro[\"Uid\"][i]] ###修改his可以获得训练集与测试集不同负样本\n",
    "        tempNe = []\n",
    "        for e in top:\n",
    "            if e not in temp:\n",
    "                tempNe.append(e)\n",
    "        res[petro[\"Uid\"][i]] = copy.deepcopy(tempNe)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 得到正负样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "#得到训练集每个用户history （以下数据结构均为字典形式 Uid:[Nid]）\n",
    "train_history = gethistory(train_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "#得到测试集每个用户history\n",
    "test_history = gethistory(test_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "#得到训练集未读的热门新闻样本\n",
    "train_Neg = getNeg_train(train_u,trainTop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "#得到测试集未读的热门新闻样本\n",
    "test_Neg = getNeg_test(test_u,testTop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 得到特征向量与标签的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用于得到训练集每个Uid特征向量与标签\n",
    "def gettrain_xy(Uid):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in train_history[Uid]:\n",
    "        x.append((train_nC.loc[train_nC[\"Nid\"]==i,col]).values.tolist()[0])\n",
    "        y.append(1)\n",
    "    for i in train_Neg[Uid]:\n",
    "        x.append((train_nC.loc[train_nC[\"Nid\"]==i,col]).values.tolist()[0])\n",
    "        y.append(0)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用于得到测试集每个Uid特征向量与标签\n",
    "def gettest_xy(Uid):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in test_history[Uid]:\n",
    "        x.append((test_nC.loc[test_nC[\"Nid\"]==i,col]).values.tolist()[0])\n",
    "        y.append(1)\n",
    "    for i in test_Neg[Uid]:\n",
    "        x.append((test_nC.loc[test_nC[\"Nid\"]==i,col]).values.tolist()[0])\n",
    "        y.append(0)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在训练集上测试准确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LogisticRegression(max_iter=1000) #最大迭代次数设置为100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用于得到准确率\n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "threshold = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用于得到训练集中要预测的新闻\n",
    "def getTrain_news(i):\n",
    "    train_news = train_u.loc[i,\"Impression\"]\n",
    "    train_news = train_news.split(\" \")\n",
    "    res = []\n",
    "    for i in train_news:\n",
    "        res.append(i[:-2])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用于得到当前Uid的逻辑回归模型\n",
    "def getReg(i):\n",
    "    Uid = train_u.loc[i,\"Uid\"]\n",
    "    xy = gettrain_xy(Uid)\n",
    "    global reg\n",
    "    reg.fit(xy[0],xy[1])\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "#得到测试集的预测结果\n",
    "def getTrainRes():\n",
    "    global TP,FP,TN,FN,reg\n",
    "    for i in range(0,len(train_u)):\n",
    "        Uid = train_u.loc[i,\"Uid\"]\n",
    "        tempNews = getTrain_news(i)\n",
    "        getReg(i)\n",
    "        for e in tempNews:\n",
    "            if ( (reg.predict_proba([(train_nC.loc[train_nC[\"Nid\"]==e,col]).values.tolist()[0]]))[0][1].round(3) >= threshold) and (e in trainT[Uid]):\n",
    "                TP += 1\n",
    "            if ( (reg.predict_proba([(train_nC.loc[train_nC[\"Nid\"]==e,col]).values.tolist()[0]]))[0][1].round(3) >= threshold) and (e not in trainT[Uid]):\n",
    "                FP += 1\n",
    "            if ( (reg.predict_proba([(train_nC.loc[train_nC[\"Nid\"]==e,col]).values.tolist()[0]]))[0][1].round(3) < threshold) and (e not in trainT[Uid]):\n",
    "                TN += 1\n",
    "            if ( (reg.predict_proba([(train_nC.loc[train_nC[\"Nid\"]==e,col]).values.tolist()[0]]))[0][1].round(3) < threshold) and (e  in trainT[Uid]):\n",
    "                FN += 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getTrainRes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5418797091054917"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(TP+TN)/(TP+TN+FP+FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 得到在测试集上的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用于得到每个test里Uid的待评测新闻\n",
    "def getTestnews(i):\n",
    "    testnews = test_u.loc[i,\"Impression\"]\n",
    "    testnews = testnews.split(\" \")\n",
    "    return testnews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用于得到当前Uid的逻辑回归模型_test\n",
    "def getReg_test(i):\n",
    "    Uid = test_u.loc[i,\"Uid\"]\n",
    "    xy = gettest_xy(Uid)\n",
    "    global reg\n",
    "    reg.fit(xy[0],xy[1])\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPred():\n",
    "    reslis = []\n",
    "    for i in range(0,len(test_u)):\n",
    "        Uid = train_u.loc[i,\"Uid\"]\n",
    "        sample = getTestnews(i)\n",
    "        getReg_test(i)\n",
    "        strTemp = \"\"\n",
    "        for e in sample:\n",
    "            strTemp = strTemp +  str((reg.predict_proba([(test_nC.loc[test_nC[\"Nid\"]==e,col]).values.tolist()[0]]))[0][1].round(3))+\" \"\n",
    "        reslis.append([strTemp])\n",
    "    coll = [\"Predict\"]\n",
    "    res =  pd.DataFrame(reslis,columns=coll)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predict = getPred()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([test_u,Predict],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"test_res.tsv\",index=False, sep='\\t', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
